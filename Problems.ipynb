{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "#random.seed(5918)\n",
    "#np.random.seed(5918)\n",
    "import os\n",
    "import re\n",
    "\n",
    "from ast import literal_eval as make_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_map_with_clusters(n_nodes_per_cluster:int, n_clusters:int,cluster_radius = 200):\n",
    "\n",
    "    max_x = 1000\n",
    "    max_y = 1000\n",
    "    \n",
    "    turbine_id = 1\n",
    "    \n",
    "    grid = {}\n",
    "    \n",
    "    grid[0] = (0,0)\n",
    "    \n",
    "    cluster_centers = []\n",
    "    cs = []\n",
    "    \n",
    "    for _ in range(n_clusters):\n",
    "        angle = random.uniform(0,math.pi/2)\n",
    "        \n",
    "        apexx = int(cluster_radius*math.cos(angle))\n",
    "        apexy = int(cluster_radius*math.sin(angle))\n",
    "        cx = round(random.uniform(apexx, max_x))\n",
    "        cy = round(random.uniform(apexy,max_y))\n",
    "        cluster_centers.append((cx,cy))\n",
    "        grid[turbine_id] = (cx,cy)\n",
    "        cs.append(turbine_id)\n",
    "        turbine_id+=1\n",
    "        \n",
    "    for cluster in cluster_centers:\n",
    "        cx,cy = cluster\n",
    "    \n",
    "        for _ in range(n_nodes_per_cluster):\n",
    "            x = int(random.gauss(cx,50))\n",
    "            y = int(random.gauss(cy,50))\n",
    "            \n",
    "            x = max(0,min(x,max_x))\n",
    "            y = max(0,min(y,max_y))\n",
    "            \n",
    "            grid[turbine_id] = (x,y)\n",
    "            turbine_id +=1\n",
    "    \n",
    "\n",
    "    return grid,cs,cluster_centers\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jobs(nodes:dict,n_chargers): #The nodes here should only be the OTWs\n",
    "    \"\"\"This function generates jobs for the problem. The crew_needed for each job states how much of the passanger capacity the crew for this job takes in the vessel. The priority property is used\n",
    "    in the objective function in the case that a job is left unserved. A higher priority yields a larger penalty. This function can be expanded to give more parameters to the jobs-\n",
    "\n",
    "    Args:\n",
    "        nodes (dict): All the nodes in the problem\n",
    "        n_chargers (int): The number of chargers in the problem. This is used to find the correct index of the OTW-nodes\n",
    "\n",
    "    Returns:\n",
    "        jobs (dict): All the jobs with turbine_id as key and (crew_needed, priority) as value. \n",
    "    \"\"\"\n",
    "    #np.random.seed(5918)\n",
    "    n_nodes = len(nodes)\n",
    "    \n",
    "    crew_needed = np.clip(np.random.normal(loc=5, scale=2, size=n_nodes).astype(int), a_min=1, a_max=None)\n",
    "    crew_needed = crew_needed.tolist()\n",
    "\n",
    "    \n",
    "    jobs = {}\n",
    "    for i in range(n_chargers+1,n_nodes):\n",
    "        tag = i\n",
    "        job = crew_needed.pop()\n",
    "        jobs[tag] = job\n",
    "\n",
    "    return jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test = make_a_test_map(10)\\ntour1, len1 = make_tour(test,3)\\ntour2, len2 = make_tour(test,2)\\ncluster_test, centers = make_a_test_map_with_clusters(3,3,35)\\nclustertour1, clustertourlength1 = make_tour(cluster_test,4)\\nclustertour2, clustertourlength2 = make_tour(cluster_test,3)\\n'"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test = make_a_test_map(10)\n",
    "tour1, len1 = make_tour(test,3)\n",
    "tour2, len2 = make_tour(test,2)\n",
    "cluster_test, centers = make_a_test_map_with_clusters(3,3,35)\n",
    "clustertour1, clustertourlength1 = make_tour(cluster_test,4)\n",
    "clustertour2, clustertourlength2 = make_tour(cluster_test,3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'clusterplot = show_the_grid(cluster_test,len(centers))\\nplot_tour_on_map(clusterplot,cluster_test,clustertour1,clustertourlength1,\"Tour 1\")\\nplot_tour_on_map(clusterplot,cluster_test,clustertour2,clustertourlength2,\"Tour 2\",color = \\'purple\\')\\nplot_cluster_centers(clusterplot,centers,30)\\nprint(clustertour2)'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''clusterplot = show_the_grid(cluster_test,len(centers))\n",
    "plot_tour_on_map(clusterplot,cluster_test,clustertour1,clustertourlength1,\"Tour 1\")\n",
    "plot_tour_on_map(clusterplot,cluster_test,clustertour2,clustertourlength2,\"Tour 2\",color = 'purple')\n",
    "plot_cluster_centers(clusterplot,centers,30)\n",
    "print(clustertour2)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarlolength():\n",
    "    '''\n",
    "    I want this function to make 10 grids, and for each grid to make 10000 tours of tourlength tourlength.\n",
    "    I should then check that each node is visited evenly, and primarily it should calculate the average length of the tours\n",
    "    '''\n",
    "    avgs = np.zeros(4)\n",
    "    i_s = 10\n",
    "    j_s = 100000\n",
    "    for n in range(1,5):\n",
    "        \n",
    "        for i in range(i_s):\n",
    "            \n",
    "            curr_map = make_a_test_map(15)\n",
    "            \n",
    "            for j in range(j_s):\n",
    "                tour, tourlength = make_tour(curr_map,n)\n",
    "                avgs[n-1] += tourlength/(i_s*j_s)\n",
    "    \n",
    "    \n",
    "    return avgs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def montecarlolength_cluster():\n",
    "    '''\n",
    "    I want this function to make 10 grids, and for each grid to make 10000 tours of tourlength tourlength.\n",
    "    I should then check that each node is visited evenly, and primarily it should calculate the average length of the tours\n",
    "    '''\n",
    "    avgs = np.zeros(4)\n",
    "    i_s = 10\n",
    "    j_s = 100000\n",
    "    for n in range(1,5):\n",
    "        \n",
    "        for i in range(i_s):\n",
    "            \n",
    "            curr_map,_, _ = make_map_with_clusters(6,1,20)\n",
    "            \n",
    "            for j in range(j_s):\n",
    "                tour, tourlength = make_tour(curr_map,n)\n",
    "                avgs[n-1] += tourlength/(i_s*j_s)\n",
    "    \n",
    "    \n",
    "    return avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lengths = montecarlolength()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster_lengths = montecarlolength_cluster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vessel_types():\n",
    "    vessels = {}\n",
    "    #ID: The keys in the dictionary is the vessel id.\n",
    "    battery_range = [2000,3000,4500] # I think these ranges should be okay for now since it allows the medium and big vessel type to go to more than one cluster\n",
    "    #coeffecient = [] #kWh / km \n",
    "    operational_cost = [1, 2, 3.5] #cost per km\n",
    "    speed = [20,22,25] # Knots. In km/h: 37,41,46\n",
    "    passenger_capacity = [10,15,25] # This will be modified depending on the avg size of the crews.\n",
    "    fixed_cost = [5000,10000,17000]\n",
    "    \n",
    "    \n",
    "    vessels[1] = [1,battery_range[0],operational_cost[0],speed[0], passenger_capacity[0],fixed_cost[0]]\n",
    "    vessels[2] = [2,battery_range[1],operational_cost[1],speed[1], passenger_capacity[1],fixed_cost[1]]\n",
    "    vessels[3] = [3,battery_range[2],operational_cost[2],speed[2], passenger_capacity[2],fixed_cost[2]]\n",
    "    \n",
    "    return vessels\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_nodes(jobs):\n",
    "    \n",
    "    nodes = []\n",
    "    \n",
    "    for job in jobs.keys():\n",
    "        nodes.append((job,0))\n",
    "        nodes.append((job,1))\n",
    "    \n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_problem(n_nodes_per_cluster, n_chargers,n_trips,print_=True):\n",
    "    \n",
    "    #random.seed(5918)\n",
    "    \n",
    "    problem = {}\n",
    "    \n",
    "    locations, cs, cs_locations = make_map_with_clusters(n_nodes_per_cluster=n_nodes_per_cluster,n_clusters=n_chargers)\n",
    "    problem[\"Locations\"] = locations\n",
    "    charging_stations = list(zip(cs,cs_locations))\n",
    "    \n",
    "    problem[\"ChargingStations\"] = charging_stations\n",
    "    \n",
    "    \n",
    "    jobs = generate_jobs(locations,len(charging_stations))\n",
    "    problem[\"Jobs\"] = jobs\n",
    "    \n",
    "    \n",
    "    nodes = all_nodes(jobs)\n",
    "    \n",
    "    problem[\"Nodes\"] = nodes\n",
    "    \n",
    "    vessels = vessel_types()\n",
    "    problem[\"Vessels\"] = vessels\n",
    "    \n",
    "    problem[\"N_trips\"] = n_trips\n",
    "    \n",
    "    \n",
    "    costs = {\"Fixed Penalty\": 2000, #Penalty for each crew member outsourced. This makes a bigger job be more prenalized than a smaller job\n",
    "             \"PenaltyPerCrew\": 750\n",
    "            }\n",
    "    problem[\"Costs\"] = costs\n",
    "    \n",
    "    pp = preprocessing(problem)\n",
    "    \n",
    "    problem[\"PreProseccing\"] = pp\n",
    "    \n",
    "    if print_:\n",
    "        print(\"Jobs Information:\")\n",
    "        print(\"{:<15} {:<15}\".format(\"Turbine ID\", \"Crew Needed\"))\n",
    "        for turbine_id, (crew_needed) in jobs.items():\n",
    "            print(\"{:<15} {:<15}\".format(turbine_id, crew_needed))\n",
    "        \n",
    "        print(\"Vessel Types Information:\")\n",
    "        print(\"{:<10} {:<15} {:<20} {:<25} {:<20} {:<20}\".format(\"Vessel ID\", \"Battery Range\", \"Operational Cost\", \"Speed (Knots)\", \"Passenger Capacity\", \"Fixed Cost\"))\n",
    "        for specs in vessels.values():\n",
    "            vessel_id, battery_range, operational_cost, speed, passenger_capacity,fixed_cost = specs\n",
    "            print(\"{:<10} {:<15} {:<20} {:<25} {:<20} {:<20}\".format(vessel_id, battery_range, operational_cost, speed, passenger_capacity,fixed_cost))\n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    return problem\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_problem_to_file(problem, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Header and data for locations\n",
    "        file.write(\"% number of locations\\n\")\n",
    "        file.write(f\"{len(problem['Locations'])}\\n\")\n",
    "        file.write(\"% for each location: node, x, y\\n\")\n",
    "        for node_id, (x, y) in problem['Locations'].items():\n",
    "            file.write(f\"{node_id}, {x}, {y}\\n\")\n",
    "        # Number of vessels\n",
    "        file.write(\"% number of vessels\\n\")\n",
    "        file.write(f\"{problem['N_trips']}\\n\")\n",
    "        # Number and details of vessels\n",
    "        file.write(\"% number of vessel types\\n\")\n",
    "        file.write(f\"{len(problem['Vessels'].keys())}\\n\")\n",
    "        file.write(\"% for each vesseltype: vessel_id, battery range, operational cost, speed, passenger capacity, fixed cost\\n\")\n",
    "        for vessel_id, specs in problem['Vessels'].items():\n",
    "            file.write(f\"{specs[0]}, {specs[1]}, {specs[2]}, {specs[3]}, {specs[4]}, {specs[5]} \\n\")\n",
    "            \n",
    "        # Header and data for charging stations\n",
    "        file.write(\"% number of charging stations\\n\")\n",
    "        file.write(f\"{len(problem['ChargingStations'])}\\n\")\n",
    "        file.write(\"% for each charging station: node, x, y\\n\")\n",
    "        for station_id, (x, y) in problem['ChargingStations']:\n",
    "            file.write(f\"{station_id}, {x}, {y}\\n\")\n",
    "            \n",
    "        # Header and data for jobs\n",
    "        file.write(\"% number of jobs\\n\")\n",
    "        file.write(f\"{len(problem['Jobs'])}\\n\")\n",
    "        file.write(\"% for each job: node, crew needed\\n\")\n",
    "        for node_id, crew_needed in problem['Jobs'].items():\n",
    "            file.write(f\"{node_id}, {crew_needed}\\n\")\n",
    "        \n",
    "        # Header and data for nodes\n",
    "        file.write(\"% number of nodes\\n\")\n",
    "        file.write(f\"{len(problem['Nodes'])}\\n\")\n",
    "        file.write(\"% for each node: node, binary\\n\")\n",
    "        for node_id, binary in problem['Nodes']:\n",
    "            file.write(f\"{node_id}, {binary}\\n\")\n",
    "            \n",
    "        #Header and data for costs\n",
    "        file.write(\"% costs\\n\")\n",
    "        file.write(\"% fixed penalty\\n\")\n",
    "        file.write(f\"{problem['Costs']['Fixed Penalty']}\\n\")\n",
    "        file.write(\"% penalty per crew\\n\")\n",
    "        file.write(f\"{problem['Costs']['PenaltyPerCrew']}\\n\")\n",
    "        \n",
    "        #Header and data for preprocessing\n",
    "        file.write(\"% preprocessing\\n\")\n",
    "         # Assuming 'preprocessing' is the correct dictionary key in your problem\n",
    "        preprocessing = problem.get('PreProseccing', {})  # Using 'get' to avoid KeyError if missing\n",
    "        for key, arr in preprocessing.items():\n",
    "            file.write(f\"% {key} \\n\")  # Writing the key\n",
    "            for row in arr:\n",
    "                # Writing each row of the array, values separated by commas\n",
    "                row_str = \", \".join(map(str, row))\n",
    "                file.write(f\"{row_str}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_preprocessing_matrices(lines, n_nodes, is_tuple_array=False):\n",
    "    \"\"\"\n",
    "    Parses lines into a numpy matrix, with special handling for arrays containing tuples.\n",
    "    \n",
    "    Args:\n",
    "    - lines (list of str): The lines from the file to be parsed.\n",
    "    - n_nodes (int): The number of nodes, which determines the matrix size (n_nodes x n_nodes).\n",
    "    - is_tuple_array (bool): Flag to indicate if the array contains tuples, requiring special parsing.\n",
    "    \n",
    "    Returns:\n",
    "    - np.array: The parsed matrix.\n",
    "    \"\"\"\n",
    "    type = object if is_tuple_array else float\n",
    "    matrix_data = np.empty((n_nodes, n_nodes),dtype=type)\n",
    "    for i in range(n_nodes):\n",
    "        line = lines[i]\n",
    "        if is_tuple_array:\n",
    "            row = make_tuple(line)\n",
    "        else:\n",
    "            row = [float(value) for value in line.split(', ')]\n",
    "        for j in range(n_nodes):\n",
    "            element = row[j]\n",
    "            matrix_data[i, j] = element    \n",
    "        \n",
    "    return matrix_data, lines[n_nodes:]\n",
    "\n",
    "def read_problem_from_file(file_path):\n",
    "    problem = {\n",
    "        \"Locations\": {},\n",
    "        \"Vessels\": {},\n",
    "        \"ChargingStations\": [],\n",
    "        \"Jobs\": {},\n",
    "        \"Nodes\": [],\n",
    "        \"Costs\": {},\n",
    "        \"PreProseccing\": {\n",
    "            \"PreferredCS\": None,\n",
    "            \"Distances\": None,\n",
    "            \"DistancesWithCharging\": None\n",
    "        }\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = [line.strip() for line in file if line.strip() and not line.startswith('%')]\n",
    "        \n",
    "    lines_iter = iter(lines)\n",
    "    n_locations = int(next(lines_iter))\n",
    "    for _ in range(n_locations):\n",
    "        node_id, x, y = map(int, next(lines_iter).split(', '))\n",
    "        problem[\"Locations\"][int(node_id)] = (int(x), int(y))\n",
    "        \n",
    "    problem[\"N_trips\"] = int(next(lines_iter))\n",
    "\n",
    "    n_vessels = int(next(lines_iter))\n",
    "    for _ in range(n_vessels):\n",
    "        parts = list(map(float, next(lines_iter).split(', ')))\n",
    "        parts[0] = int(parts[0])\n",
    "        problem[\"Vessels\"][int(parts[0])] = parts\n",
    "\n",
    "    n_charging_stations = int(next(lines_iter))\n",
    "    for _ in range(n_charging_stations):\n",
    "        station_id, x, y = map(int, next(lines_iter).split(', '))\n",
    "        problem[\"ChargingStations\"].append((int(station_id), (int(x), int(y))))\n",
    "\n",
    "    n_jobs = int(next(lines_iter))\n",
    "    for _ in range(n_jobs):\n",
    "        job_id, crew_needed = map(int, next(lines_iter).split(', '))\n",
    "        problem[\"Jobs\"][int(job_id)] = int(crew_needed)\n",
    "\n",
    "    n_nodes = int(next(lines_iter))\n",
    "    for _ in range(n_nodes):  # Assuming twice the number of nodes for binary values\n",
    "        parts = next(lines_iter).split(', ')\n",
    "        node_id, binary = int(parts[0]), int(parts[1])\n",
    "        problem[\"Nodes\"].append((int(node_id), int(binary)))\n",
    "\n",
    "    problem[\"Costs\"][\"Fixed Penalty\"] = int(next(lines_iter))\n",
    "    problem[\"Costs\"][\"PenaltyPerCrew\"] = int(next(lines_iter))\n",
    "    \n",
    "    \n",
    "    # Moving directly to preprocessing parsing for demonstration\n",
    "    preprocessing_keys = [\"PreferredCS\", \"Distances\", \"DistancesWithCharging\"]\n",
    "    remaining_lines = list(lines_iter)  # Get remaining lines for preprocessing\n",
    "    for key in preprocessing_keys:\n",
    "        if key == \"PreferredCS\":  # This key requires special handling for tuples\n",
    "            matrix, remaining_lines = parse_preprocessing_matrices(remaining_lines, n_locations, is_tuple_array=True)\n",
    "        else:\n",
    "            matrix, remaining_lines = parse_preprocessing_matrices(remaining_lines, n_locations)\n",
    "        problem[\"PreProseccing\"][key] = matrix\n",
    "\n",
    "    return problem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_problems(folder_path):\n",
    "    problem_list = []\n",
    "    files = os.listdir(folder_path)\n",
    "    files = sorted(files, key=lambda name: int(re.match(r'(\\d+)job', name).group(1)))\n",
    "    for file in files:\n",
    "        full_file_path = os.path.join(folder_path, file)\n",
    "        problem = read_problem_from_file(full_file_path)\n",
    "        problem_list.append(problem)\n",
    "    return problem_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
